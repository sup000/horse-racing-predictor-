import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import warnings
from typing import List, Dict, Tuple, Any


warnings.filterwarnings('ignore') # Suppress warnings for cleaner output

print("Starting horse racing predictor simulation...")

# --- 1. Simulate Data ---
# In a real scenario, this would be scraped/downloaded from racing databases.

num_races = 500
horses_per_race = 10
total_horses = num_races * horses_per_race
unique_horses = 2000
unique_jockeys = 200
unique_trainers = 150

data = []
for i in range(num_races):
    race_id = f'RACE_{i:04d}'
    race_distance = np.random.choice([1000, 1200, 1400, 1600, 1800, 2000, 2400]) # meters
    race_class = np.random.choice(['Maiden', 'Claiming', 'Allowance', 'Grade 3', 'Grade 2', 'Grade 1'])
    going = np.random.choice(['Fast', 'Good', 'Soft', 'Heavy'])

  
    jockey_skills = {f'J_{j}': np.random.uniform(0.05, 0.25) for j in range(unique_jockeys)}
    trainer_skills = {f'T_{t}': np.random.uniform(0.08, 0.30) for t in range(unique_trainers)}
    horse_base_speeds = {f'H_{h}': np.random.uniform(80, 120) for h in range(unique_horses)}


    potential_winners = []
    for h in range(horses_per_race):
        horse_id = f'H_{np.random.randint(0, unique_horses)}'
        jockey_id = f'J_{np.random.randint(0, unique_jockeys)}'
        trainer_id = f'T_{np.random.randint(0, unique_trainers)}'

        horse_age = np.random.randint(3, 8)
        weight_carried = np.random.uniform(50, 65) # kg
        days_since_last_run = np.random.randint(10, 120)
        
       
        prev_speed_figure = horse_base_speeds[horse_id] + np.random.uniform(-5, 5)

        jockey_win_perc = jockey_skills[jockey_id] + np.random.uniform(-0.02, 0.02)
        trainer_win_perc = trainer_skills[trainer_id] + np.random.uniform(-0.03, 0.03)

     
        true_performance_score = (
            prev_speed_figure * 0.4
            + (1 - (weight_carried / 65)) * 10 # lower weight is better
            + (1 - (days_since_last_run / 120)) * 5 # not too long off, not too short
            + (jockey_win_perc * 100) * 0.3
            + (trainer_win_perc * 100) * 0.3
            + np.random.normal(0, 5) # Random noise
        )
        potential_winners.append({'horse_id': horse_id, 'performance_score': true_performance_score,
                                  'jockey_id': jockey_id, 'trainer_id': trainer_id,
                                  'horse_age': horse_age, 'weight_carried': weight_carried,
                                  'days_since_last_run': days_since_last_run,
                                  'prev_speed_figure': prev_speed_figure,
                                  'jockey_win_perc': jockey_win_perc,
                                  'trainer_win_perc': trainer_win_perc,
                                  'race_id': race_id, 'race_distance': race_distance,
                                  'race_class': race_class, 'going': going})


    potential_winners.sort(key=lambda x: x['performance_score'], reverse=True)
    for idx, horse_data in enumerate(potential_winners):
        horse_data['Wins'] = 1 if idx == 0 else 0
        data.append(horse_data)

df = pd.DataFrame(data)
print(f"Simulated {len(df)} horse entries across {num_races} races.")
print("Sample Data Head:")
print(df.head())
print("\nTarget Distribution (Wins):")
print(df['Wins'].value_counts(normalize=True))

# --- 2. Feature Engineering ---


def calculate_relative_features(df_race):
    df_race['relative_speed_figure'] = df_race['prev_speed_figure'] - df_race['prev_speed_figure'].mean()
    df_race['relative_weight'] = df_race['weight_carried'] - df_race['weight_carried'].mean()
    df_race['relative_jockey_win_perc'] = df_race['jockey_win_perc'] - df_race['jockey_win_perc'].mean()
    df_race['relative_trainer_win_perc'] = df_race['trainer_win_perc'] - df_race['trainer_win_perc'].mean()
    return df_race

print("\nCalculating relative features...")
df = df.groupby('race_id').apply(calculate_relative_features).reset_index(drop=True)
print("Relative features added.")


X = df.drop('Wins', axis=1)
y = df['Wins']


X = X.drop(['race_id', 'horse_id'], axis=1) # Horse ID could be used with embedding, but for simplicity we drop it


numerical_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes(include='object').columns.tolist()

print(f"\nNumerical features: {numerical_cols}")
print(f"Categorical features: {categorical_cols}")

# --- 3. Preprocessing Pipeline ---

numerical_transformer = StandardScaler()


categorical_transformer = OneHotEncoder(handle_unknown='ignore')


preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# --- 4. Model Training ---


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"\nTraining data shape: {X_train.shape}")
print(f"Testing data shape: {X_test.shape}")
print(f"Training target distribution:\n{y_train.value_counts(normalize=True)}")
print(f"Testing target distribution:\n{y_test.value_counts(normalize=True)}")


model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))])

print("\nTraining Random Forest model...")
model_pipeline.fit(X_train, y_train)
print("Model training complete.")

# --- 5. Evaluation ---

print("\n--- Model Evaluation ---")

y_pred = model_pipeline.predict(X_test)
y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1] # Probability of winning

print("\nAccuracy Score:")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")

print("\nClassification Report (Focus on '1' class for winning):")
print(classification_report(y_test, y_pred, target_names=['Does Not Win', 'Wins']))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))


auc_score = roc_auc_score(y_test, y_pred_proba)
print(f"\nROC AUC Score: {auc_score:.4f}")


try:
    ohe_feature_names = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_cols)
    all_feature_names = numerical_cols + list(ohe_feature_names)
    importances = model_pipeline.named_steps['classifier'].feature_importances_
    feature_importances_df = pd.DataFrame({'Feature': all_feature_names, 'Importance': importances})
    feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False).head(10)
    print("\nTop 10 Feature Importances:")
    print(feature_importances_df)
except Exception as e:
    print(f"\nCould not display feature importances due to pipeline complexity: {e}")
    print("This is common when using ColumnTransformer and Pipelines. You'd need more advanced methods to map back.")


# --- 6. Prediction on New Data (Example) ---
print("\n--- Predicting on New Race Data ---")


new_race_data = pd.DataFrame([
    {
        'horse_id': 'H_NEW_1', 'jockey_id': 'J_50', 'trainer_id': 'T_20',
        'horse_age': 4, 'weight_carried': 58, 'days_since_last_run': 30,
        'prev_speed_figure': 115, 'jockey_win_perc': 0.22, 'trainer_win_perc': 0.25,
        'race_id': 'RACE_NEW_1', 'race_distance': 1400, 'race_class': 'Grade 2', 'going': 'Good'
    },
    {
        'horse_id': 'H_NEW_2', 'jockey_id': 'J_10', 'trainer_id': 'T_05',
        'horse_age': 5, 'weight_carried': 60, 'days_since_last_run': 45,
        'prev_speed_figure': 105, 'jockey_win_perc': 0.18, 'trainer_win_perc': 0.19,
        'race_id': 'RACE_NEW_1', 'race_distance': 1400, 'race_class': 'Grade 2', 'going': 'Good'
    },
    {
        'horse_id': 'H_NEW_3', 'jockey_id': 'J_150', 'trainer_id': 'T_100',
        'horse_age': 3, 'weight_carried': 55, 'days_since_last_run': 25,
        'prev_speed_figure': 120, 'jockey_win_perc': 0.20, 'trainer_win_perc': 0.23,
        'race_id': 'RACE_NEW_1', 'race_distance': 1400, 'race_class': 'Grade 2', 'going': 'Good'
    },
    {
        'horse_id': 'H_NEW_4', 'jockey_id': 'J_75', 'trainer_id': 'T_30',
        'horse_age': 6, 'weight_carried': 62, 'days_since_last_run': 50,
        'prev_speed_figure': 100, 'jockey_win_perc': 0.15, 'trainer_win_perc': 0.17,
        'race_id': 'RACE_NEW_1', 'race_distance': 1400, 'race_class': 'Grade 2', 'going': 'Good'
    }
])


new_race_data_processed = new_race_data.groupby('race_id').apply(calculate_relative_features).reset_index(drop=True)


X_new_race = new_race_data_processed.drop(['race_id', 'horse_id'], axis=1)

print("\nNew Race Horses Data (after relative feature calculation):")
print(X_new_race)


predictions_proba = model_pipeline.predict_proba(X_new_race)[:, 1] # Probability of winning

new_race_results = pd.DataFrame({
    'Horse_ID': new_race_data_processed['horse_id'],
    'Predicted_Win_Probability': predictions_proba
})

new_race_results = new_race_results.sort_values(by='Predicted_Win_Probability', ascending=False)

print("\nPredicted Win Probabilities for New Race:")
print(new_race_results)


predicted_winner = new_race_results.iloc[0]
print(f"\nBased on current model, the predicted winner is: {predicted_winner['Horse_ID']} with {predicted_winner['Predicted_Win_Probability']:.2%} probability.")

print("\n--- Simulation Complete ---")
print("\nRemember, this is a highly simplified and experimental model. Do NOT use for actual betting.")
